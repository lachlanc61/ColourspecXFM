{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lachlan/.pyenv/versions/venv_readoutxfm/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script: /home/lachlan/CODEBASE/ReadoutXFM/config.py\n",
      "script path: /home/lachlan/CODEBASE/ReadoutXFM\n",
      "data path: /home/lachlan/CODEBASE/ReadoutXFM/data\n",
      "---------------\n",
      "opening .geo: geo_ln_chle\n",
      "---------------------------\n",
      "EXTRACTING SPECTRA\n",
      "---------------------------\n",
      "filesize: 198419529 (bytes)\n",
      "header length: 1503 bytes\n",
      "map dimensions x,y = 400,169 px\n",
      "pixels expected: 67600\n",
      "---------------------------\n",
      "Row 0/169 at pixel 0, byte 1505 (0.0 %)\n",
      "Row 1/169 at pixel 400, byte 1172821 (0.6 %)\n",
      "Row 2/169 at pixel 800, byte 2348429 (1.2 %)\n",
      "Row 3/169 at pixel 1200, byte 3522545 (1.8 %)\n",
      "Row 4/169 at pixel 1600, byte 4701725 (2.4 %)\n",
      "Row 5/169 at pixel 2000, byte 5886737 (3.0 %)\n",
      "Row 6/169 at pixel 2400, byte 7080321 (3.6 %)\n",
      "Row 7/169 at pixel 2800, byte 8286661 (4.2 %)\n",
      "Row 8/169 at pixel 3200, byte 9493117 (4.8 %)\n",
      "Row 9/169 at pixel 3600, byte 10700801 (5.4 %)\n",
      "Row 10/169 at pixel 4000, byte 11911537 (6.0 %)\n",
      "Row 11/169 at pixel 4400, byte 13117609 (6.6 %)\n",
      "Row 12/169 at pixel 4800, byte 14319861 (7.2 %)\n",
      "Row 13/169 at pixel 5200, byte 15512777 (7.8 %)\n",
      "Row 14/169 at pixel 5600, byte 16704581 (8.4 %)\n",
      "Row 15/169 at pixel 6000, byte 17894641 (9.0 %)\n",
      "Row 16/169 at pixel 6400, byte 19083077 (9.6 %)\n",
      "Row 17/169 at pixel 6800, byte 20273757 (10.2 %)\n",
      "Row 18/169 at pixel 7200, byte 21464541 (10.8 %)\n",
      "Row 19/169 at pixel 7600, byte 22659633 (11.4 %)\n",
      "Row 20/169 at pixel 8000, byte 23853409 (12.0 %)\n",
      "Row 21/169 at pixel 8400, byte 25047653 (12.6 %)\n",
      "Row 22/169 at pixel 8800, byte 26241889 (13.2 %)\n",
      "Row 23/169 at pixel 9200, byte 27435681 (13.8 %)\n",
      "Row 24/169 at pixel 9600, byte 28635717 (14.4 %)\n",
      "Row 25/169 at pixel 10000, byte 29838021 (15.0 %)\n",
      "Row 26/169 at pixel 10400, byte 31044461 (15.6 %)\n",
      "Row 27/169 at pixel 10800, byte 32256329 (16.3 %)\n",
      "Row 28/169 at pixel 11200, byte 33472269 (16.9 %)\n",
      "Row 29/169 at pixel 11600, byte 34691769 (17.5 %)\n",
      "Row 30/169 at pixel 12000, byte 35914185 (18.1 %)\n",
      "Row 31/169 at pixel 12400, byte 37133625 (18.7 %)\n",
      "Row 32/169 at pixel 12800, byte 38350157 (19.3 %)\n",
      "Row 33/169 at pixel 13200, byte 39562321 (19.9 %)\n",
      "Row 34/169 at pixel 13600, byte 40765437 (20.5 %)\n",
      "Row 35/169 at pixel 14000, byte 41953841 (21.1 %)\n",
      "Row 36/169 at pixel 14400, byte 43136553 (21.7 %)\n",
      "Row 37/169 at pixel 14800, byte 44305837 (22.3 %)\n",
      "Row 38/169 at pixel 15200, byte 45468089 (22.9 %)\n",
      "Row 39/169 at pixel 15600, byte 46620109 (23.5 %)\n",
      "Row 40/169 at pixel 16000, byte 47772341 (24.1 %)\n",
      "Row 41/169 at pixel 16400, byte 48920209 (24.7 %)\n",
      "Row 42/169 at pixel 16800, byte 50063721 (25.2 %)\n",
      "Row 43/169 at pixel 17200, byte 51209789 (25.8 %)\n",
      "Row 44/169 at pixel 17600, byte 52362437 (26.4 %)\n",
      "Row 45/169 at pixel 18000, byte 53509829 (27.0 %)\n",
      "Row 46/169 at pixel 18400, byte 54662481 (27.5 %)\n",
      "Row 47/169 at pixel 18800, byte 55815725 (28.1 %)\n",
      "Row 48/169 at pixel 19200, byte 56966673 (28.7 %)\n",
      "Row 49/169 at pixel 19600, byte 58123089 (29.3 %)\n",
      "Row 50/169 at pixel 20000, byte 59284137 (29.9 %)\n",
      "Row 51/169 at pixel 20400, byte 60452941 (30.5 %)\n",
      "Row 52/169 at pixel 20800, byte 61621885 (31.1 %)\n",
      "Row 53/169 at pixel 21200, byte 62800457 (31.7 %)\n",
      "Row 54/169 at pixel 21600, byte 63984453 (32.2 %)\n",
      "Row 55/169 at pixel 22000, byte 65170029 (32.8 %)\n",
      "Row 56/169 at pixel 22400, byte 66349645 (33.4 %)\n",
      "Row 57/169 at pixel 22800, byte 67524749 (34.0 %)\n",
      "Row 58/169 at pixel 23200, byte 68699149 (34.6 %)\n",
      "Row 59/169 at pixel 23600, byte 69874353 (35.2 %)\n",
      "Row 60/169 at pixel 24000, byte 71042793 (35.8 %)\n",
      "Row 61/169 at pixel 24400, byte 72209981 (36.4 %)\n",
      "Row 62/169 at pixel 24800, byte 73377049 (37.0 %)\n",
      "Row 63/169 at pixel 25200, byte 74542137 (37.6 %)\n",
      "Row 64/169 at pixel 25600, byte 75711985 (38.2 %)\n",
      "Row 65/169 at pixel 26000, byte 76883441 (38.7 %)\n",
      "Row 66/169 at pixel 26400, byte 78057085 (39.3 %)\n",
      "Row 67/169 at pixel 26800, byte 79226133 (39.9 %)\n",
      "Row 68/169 at pixel 27200, byte 80390245 (40.5 %)\n",
      "Row 69/169 at pixel 27600, byte 81550137 (41.1 %)\n",
      "Row 70/169 at pixel 28000, byte 82708885 (41.7 %)\n",
      "Row 71/169 at pixel 28400, byte 83862329 (42.3 %)\n",
      "Row 72/169 at pixel 28800, byte 85014965 (42.8 %)\n",
      "Row 73/169 at pixel 29200, byte 86164813 (43.4 %)\n",
      "Row 74/169 at pixel 29600, byte 87319185 (44.0 %)\n",
      "Row 75/169 at pixel 30000, byte 88473009 (44.6 %)\n",
      "Row 76/169 at pixel 30400, byte 89624741 (45.2 %)\n",
      "Row 77/169 at pixel 30800, byte 90772017 (45.7 %)\n",
      "Row 78/169 at pixel 31200, byte 91907637 (46.3 %)\n",
      "Row 79/169 at pixel 31600, byte 93042277 (46.9 %)\n",
      "Row 80/169 at pixel 32000, byte 94176065 (47.5 %)\n",
      "Row 81/169 at pixel 32400, byte 95308369 (48.0 %)\n",
      "Row 82/169 at pixel 32800, byte 96444505 (48.6 %)\n",
      "Row 83/169 at pixel 33200, byte 97585421 (49.2 %)\n",
      "Row 84/169 at pixel 33600, byte 98727029 (49.8 %)\n",
      "Row 85/169 at pixel 34000, byte 99870093 (50.3 %)\n",
      "Row 86/169 at pixel 34400, byte 101016289 (50.9 %)\n",
      "Row 87/169 at pixel 34800, byte 102167261 (51.5 %)\n",
      "Row 88/169 at pixel 35200, byte 103313021 (52.1 %)\n",
      "Row 89/169 at pixel 35600, byte 104452065 (52.6 %)\n",
      "Row 90/169 at pixel 36000, byte 105586885 (53.2 %)\n",
      "Row 91/169 at pixel 36400, byte 106717533 (53.8 %)\n",
      "Row 92/169 at pixel 36800, byte 107843337 (54.4 %)\n",
      "Row 93/169 at pixel 37200, byte 108967409 (54.9 %)\n",
      "Row 94/169 at pixel 37600, byte 110096677 (55.5 %)\n",
      "Row 95/169 at pixel 38000, byte 111230937 (56.1 %)\n",
      "Row 96/169 at pixel 38400, byte 112368837 (56.6 %)\n",
      "Row 97/169 at pixel 38800, byte 113516137 (57.2 %)\n",
      "Row 98/169 at pixel 39200, byte 114668137 (57.8 %)\n",
      "Row 99/169 at pixel 39600, byte 115821665 (58.4 %)\n",
      "Row 100/169 at pixel 40000, byte 116976373 (59.0 %)\n",
      "Row 101/169 at pixel 40400, byte 118142105 (59.5 %)\n",
      "Row 102/169 at pixel 40800, byte 119313349 (60.1 %)\n",
      "Row 103/169 at pixel 41200, byte 120490537 (60.7 %)\n",
      "Row 104/169 at pixel 41600, byte 121676693 (61.3 %)\n",
      "Row 105/169 at pixel 42000, byte 122868693 (61.9 %)\n",
      "Row 106/169 at pixel 42400, byte 124063357 (62.5 %)\n",
      "Row 107/169 at pixel 42800, byte 125252617 (63.1 %)\n",
      "Row 108/169 at pixel 43200, byte 126438713 (63.7 %)\n",
      "Row 109/169 at pixel 43600, byte 127623497 (64.3 %)\n",
      "Row 110/169 at pixel 44000, byte 128809813 (64.9 %)\n",
      "Row 111/169 at pixel 44400, byte 129998409 (65.5 %)\n",
      "Row 112/169 at pixel 44800, byte 131181657 (66.1 %)\n",
      "Row 113/169 at pixel 45200, byte 132361245 (66.7 %)\n",
      "Row 114/169 at pixel 45600, byte 133538537 (67.3 %)\n",
      "Row 115/169 at pixel 46000, byte 134717041 (67.9 %)\n",
      "Row 116/169 at pixel 46400, byte 135887473 (68.5 %)\n",
      "Row 117/169 at pixel 46800, byte 137054973 (69.1 %)\n",
      "Row 118/169 at pixel 47200, byte 138224289 (69.7 %)\n",
      "Row 119/169 at pixel 47600, byte 139392381 (70.3 %)\n",
      "Row 120/169 at pixel 48000, byte 140569789 (70.8 %)\n",
      "Row 121/169 at pixel 48400, byte 141744217 (71.4 %)\n",
      "Row 122/169 at pixel 48800, byte 142913241 (72.0 %)\n",
      "Row 123/169 at pixel 49200, byte 144085697 (72.6 %)\n",
      "Row 124/169 at pixel 49600, byte 145255953 (73.2 %)\n",
      "Row 125/169 at pixel 50000, byte 146433493 (73.8 %)\n",
      "Row 126/169 at pixel 50400, byte 147615273 (74.4 %)\n",
      "Row 127/169 at pixel 50800, byte 148795337 (75.0 %)\n",
      "Row 128/169 at pixel 51200, byte 149971073 (75.6 %)\n",
      "Row 129/169 at pixel 51600, byte 151146589 (76.2 %)\n",
      "Row 130/169 at pixel 52000, byte 152320909 (76.8 %)\n",
      "Row 131/169 at pixel 52400, byte 153497653 (77.4 %)\n",
      "Row 132/169 at pixel 52800, byte 154674853 (78.0 %)\n",
      "Row 133/169 at pixel 53200, byte 155847669 (78.5 %)\n",
      "Row 134/169 at pixel 53600, byte 157018593 (79.1 %)\n",
      "Row 135/169 at pixel 54000, byte 158187189 (79.7 %)\n",
      "Row 136/169 at pixel 54400, byte 159359457 (80.3 %)\n",
      "Row 137/169 at pixel 54800, byte 160530433 (80.9 %)\n",
      "Row 138/169 at pixel 55200, byte 161702017 (81.5 %)\n",
      "Row 139/169 at pixel 55600, byte 162867281 (82.1 %)\n",
      "Row 140/169 at pixel 56000, byte 164032221 (82.7 %)\n",
      "Row 141/169 at pixel 56400, byte 165199229 (83.3 %)\n",
      "Row 142/169 at pixel 56800, byte 166372137 (83.8 %)\n",
      "Row 143/169 at pixel 57200, byte 167541653 (84.4 %)\n",
      "Row 144/169 at pixel 57600, byte 168714145 (85.0 %)\n",
      "Row 145/169 at pixel 58000, byte 169888213 (85.6 %)\n",
      "Row 146/169 at pixel 58400, byte 171070217 (86.2 %)\n",
      "Row 147/169 at pixel 58800, byte 172252717 (86.8 %)\n",
      "Row 148/169 at pixel 59200, byte 173439569 (87.4 %)\n",
      "Row 149/169 at pixel 59600, byte 174628373 (88.0 %)\n",
      "Row 150/169 at pixel 60000, byte 175812825 (88.6 %)\n",
      "Row 151/169 at pixel 60400, byte 176999677 (89.2 %)\n",
      "Row 152/169 at pixel 60800, byte 178190693 (89.8 %)\n",
      "Row 153/169 at pixel 61200, byte 179388389 (90.4 %)\n",
      "Row 154/169 at pixel 61600, byte 180580581 (91.0 %)\n",
      "Row 155/169 at pixel 62000, byte 181768549 (91.6 %)\n",
      "Row 156/169 at pixel 62400, byte 182949629 (92.2 %)\n",
      "Row 157/169 at pixel 62800, byte 184124081 (92.8 %)\n",
      "Row 158/169 at pixel 63200, byte 185299417 (93.4 %)\n",
      "Row 159/169 at pixel 63600, byte 186474057 (94.0 %)\n",
      "Row 160/169 at pixel 64000, byte 187654625 (94.6 %)\n",
      "Row 161/169 at pixel 64400, byte 188837393 (95.2 %)\n",
      "Row 162/169 at pixel 64800, byte 190023793 (95.8 %)\n",
      "Row 163/169 at pixel 65200, byte 191206041 (96.4 %)\n",
      "Row 164/169 at pixel 65600, byte 192395317 (97.0 %)\n",
      "Row 165/169 at pixel 66000, byte 193589277 (97.6 %)\n",
      "Row 166/169 at pixel 66400, byte 194784629 (98.2 %)\n",
      "Row 167/169 at pixel 66800, byte 195989713 (98.8 %)\n",
      "Row 168/169 at pixel 67200, byte 197200897 (99.4 %)\n",
      "WARNING: pixel count 67599 exceeds expected map size 67600\n",
      "saving spectrum-by-pixel to file\n",
      "---------------------------\n",
      "MAP COMPLETE\n",
      "---------------------------\n",
      "pixels expected (X*Y): 67600\n",
      "pixels found: 67600\n",
      "total time: 80.84 s\n",
      "time per pixel: 0.001196 s\n",
      "---------------------------\n",
      "                          data: 528.1 MiB\n",
      "                        stream: 189.2 MiB\n",
      "                         pxlen: 132.1 KiB\n",
      "                          xidx: 132.1 KiB\n",
      "                          yidx: 132.1 KiB\n",
      "                           det: 132.1 KiB\n",
      "                            dt: 132.1 KiB\n",
      "                          chan: 32.1 KiB\n",
      "                        energy: 32.1 KiB\n",
      "                       outchan: 32.1 KiB\n",
      "DOCLUST False\n",
      "CLEAN EXIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsnip background\\nhttps://stackoverflow.com/questions/57350711/baseline-correction-for-spectroscopic-data\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load core.py\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import config\n",
    "import src.utils as utils\n",
    "import src.bitops as bitops\n",
    "import src.colour as colour\n",
    "import src.clustering as clustering\n",
    "\n",
    "\"\"\"\n",
    "INITIALISE data TO WHOLE MAP EVEN IF USING EARLY STOP\n",
    ".: huge memory req\n",
    "can scale that down\n",
    "\n",
    "also consider throwing away some, scaling down floats/ints etc\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Parses spectrum-by-pixel maps from IXRF XFM\n",
    "\n",
    "- parses binary .GeoPIXE files\n",
    "- extracts pixel parameters\n",
    "- projects spectra onto simple RGB channels\n",
    "- displays as RGB\n",
    "\n",
    "./data has example dataset\n",
    "\n",
    "SPEED\n",
    "                t/px\n",
    "reading only:   0.00014 \n",
    "colourmap:      0.0078\n",
    "read and clust  0.001296 \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#-----------------------------------\n",
    "#CLASSES\n",
    "#-----------------------------------\n",
    "\n",
    "#-----------------------------------\n",
    "#INITIALISE\n",
    "#-----------------------------------\n",
    "\n",
    "starttime = time.time()             #init timer\n",
    "chan=np.arange(0,config.NCHAN)      #channels\n",
    "energy=chan*config.ESTEP            #energy list\n",
    "\n",
    "#-----------------------------------\n",
    "#MAIN START\n",
    "#-----------------------------------\n",
    "\n",
    "#check filetype is recognised - currently only accepts .GeoPIXE\n",
    "if config.FTYPE == \".GeoPIXE\":\n",
    "    f = os.path.join(config.wdir,config.infile)\n",
    "    fname = os.path.splitext(os.path.basename(f))[0]\n",
    "\n",
    "    print(\"opening .geo:\",fname)\n",
    "else: \n",
    "    print(f'FATAL: filetype {config.FTYPE} not recognised')\n",
    "    exit()\n",
    "\n",
    "print(\n",
    "    \"---------------------------\\n\"\n",
    "    \"EXTRACTING SPECTRA\\n\"\n",
    "    \"---------------------------\"\n",
    ")\n",
    "\n",
    "#open the datafile \n",
    "with open(f, mode='rb') as file: # rb = read binary\n",
    "    \n",
    "    #generate bytestream\n",
    "    stream = file.read()         #NB. to read in chunks, add chunk size as read(SIZE)\n",
    "    streamlen=len(stream)\n",
    "\n",
    "    print(f\"filesize: {streamlen} (bytes)\")\n",
    "\n",
    "    headerlen=bitops.binunpack(stream,0,\"<H\")[0]\n",
    "\n",
    "    #check for header\n",
    "    #   pixels start with \"DP\" (=20550 as <uint16)\n",
    "    #   if we find this immediately, header is zero length\n",
    "    #provided header is present\n",
    "    #   read params from header\n",
    "    if headerlen == 20550:\n",
    "        print(\"WARNING: no header found\")\n",
    "        headerlen=0\n",
    "        mapx=config.MAPX\n",
    "        mapy=config.MAPY\n",
    "        print(\"WARNING: map dimensions not found\")\n",
    "        print(f\"-------using defaults {mapx},{mapy}\")\n",
    "    else:\n",
    "        \"\"\"\n",
    "        if header present, read as json\n",
    "        https://stackoverflow.com/questions/40059654/python-convert-a-bytes-array-into-json-format\n",
    "        \"\"\"\n",
    "        #pull slice of byte stream corresponding to header\n",
    "        #   bytes[0-2]= headerlen\n",
    "        #   headerlen doesn't include trailing '\\n' '}', so +2\n",
    "        headerstream=stream[2:headerlen+2]\n",
    "        #read it as utf8\n",
    "        headerstream = headerstream.decode('utf8')\n",
    "        \n",
    "        #load into dictionary via json builtin\n",
    "        headerdict = json.loads(headerstream)\n",
    "\n",
    "        #create a human-readable dump for debugging\n",
    "        headerdump = json.dumps(headerdict, indent=4, sort_keys=False)\n",
    "        \n",
    "        #get params\n",
    "        mapx=headerdict['File Header']['Xres']  #map dimension x\n",
    "        mapy=headerdict['File Header']['Yres']  #map dimension y\n",
    "\n",
    "    #assign map size based on dimensions\n",
    "    totalpx=mapx*mapy     \n",
    "\n",
    "    #print run params\n",
    "    print(f\"header length: {headerlen} bytes\")\n",
    "    print(f\"map dimensions x,y = {mapx},{mapy} px\")\n",
    "\n",
    "    #   if we are skipping some of the file\n",
    "    #       assign the ratio and adjust totalpx\n",
    "    if config.SHORTRUN:\n",
    "        skipratio=config.shortpct/100\n",
    "        trunc_y=int(np.ceil(mapy*skipratio))\n",
    "        totalpx=mapx*trunc_y\n",
    "        print(f\"SHORT RUN: ending at {skipratio*100} %\")\n",
    "\n",
    "    print(f\"pixels expected: {totalpx}\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "    if config.FORCEREAD:\n",
    "        #assign starting pixel index \n",
    "        idx=headerlen+2 #legnth of header + 2 bytes\n",
    "\n",
    "        #initialise pixel param arrays\n",
    "        pxlen=np.zeros(totalpx,dtype=np.uint16)\n",
    "        xidx=np.zeros(totalpx,dtype=np.uint16)\n",
    "        yidx=np.zeros(totalpx,dtype=np.uint16)\n",
    "        det=np.zeros(totalpx,dtype=np.uint16)\n",
    "        dt=np.zeros(totalpx,dtype=np.uint16)\n",
    "        \n",
    "        if config.DOCOLOURS == True:\n",
    "            #initalise pixel colour arrays\n",
    "            rvals=np.zeros(totalpx)\n",
    "            gvals=np.zeros(totalpx)\n",
    "            bvals=np.zeros(totalpx)\n",
    "            totalcounts=np.zeros(totalpx)\n",
    "\n",
    "        #initialise data array\n",
    "        data=np.zeros((totalpx,config.NCHAN),dtype=np.uint16)\n",
    "\n",
    "        i=0 #pixel counter\n",
    "        j=0 #row counter\n",
    "\n",
    "        #loop through pixels\n",
    "        while idx < streamlen:\n",
    "\n",
    "            #print pixel index every row px\n",
    "            if i % mapx == 0: \n",
    "                print(f\"Row {j}/{mapy} at pixel {i}, byte {idx} ({100*idx/streamlen:.1f} %)\")\n",
    "                j+=1\n",
    "\n",
    "            #read pixel record into spectrum and header param arrays, \n",
    "            # + reassign index at end of read\n",
    "            outchan, counts, pxlen[i], xidx[i], yidx[i], det[i], dt[i], idx = bitops.readpxrecord(idx, stream)\n",
    "\n",
    "            #fill gaps in spectrum \n",
    "            #   (ie. add 0s for all missing chans)\n",
    "            outchan, counts = utils.gapfill(outchan,counts, config.NCHAN)\n",
    "\n",
    "            #warn if recieved channel list is different length to chan array\n",
    "            if len(outchan) != len(chan):\n",
    "                print(\"WARNING: unexpected length of channel list\")\n",
    "        \n",
    "            #assign counts into data array - \n",
    "            data[i,:]=counts\n",
    "\n",
    "            #build colours if required\n",
    "            if config.DOCOLOURS == True: rvals[i], bvals[i], gvals[i], totalcounts[i] = colour.spectorgb(energy, counts)\n",
    "            \n",
    "            #if pixel index greater than expected no. pixels based on map dimensions\n",
    "            #   end if we are doing a truncated run\n",
    "            #   else throw a warning\n",
    "            if i >= (totalpx-1):\n",
    "                if (config.SHORTRUN == True):   #i > totalpx is expected for short run\n",
    "                    print(\"ending at:\", idx)\n",
    "                    idx=streamlen+1\n",
    "                    break \n",
    "                else:\n",
    "                    print(f\"WARNING: pixel count {i} exceeds expected map size {totalpx}\")\n",
    "            i+=1\n",
    "\n",
    "        runtime = time.time() - starttime\n",
    "\n",
    "        if config.SAVEPXSPEC:\n",
    "            print(f\"saving spectrum-by-pixel to file\")\n",
    "            np.savetxt(os.path.join(config.odir,  config.savename + \".dat\"), data, fmt='%i')\n",
    "        \n",
    "        np.savetxt(os.path.join(config.odir, \"pxlen.txt\"), pxlen, fmt='%i')\n",
    "        np.savetxt(os.path.join(config.odir, \"xidx.txt\"), xidx, fmt='%i')\n",
    "        np.savetxt(os.path.join(config.odir, \"yidx.txt\"), yidx, fmt='%i')\n",
    "        np.savetxt(os.path.join(config.odir, \"detector.txt\"), det, fmt='%i')\n",
    "        np.savetxt(os.path.join(config.odir, \"dt.txt\"), dt, fmt='%i')\n",
    "\n",
    "\n",
    "        print(\n",
    "        \"---------------------------\\n\"\n",
    "        \"MAP COMPLETE\\n\"\n",
    "        \"---------------------------\\n\"\n",
    "        f\"pixels expected (X*Y): {totalpx}\\n\"\n",
    "        f\"pixels found: {i}\\n\"\n",
    "        f\"total time: {round(runtime,2)} s\\n\"\n",
    "        f\"time per pixel: {round((runtime/i),6)} s\\n\"\n",
    "        \"---------------------------\"\n",
    "    )\n",
    "    else:\n",
    "        print(\"loading from file\", config.savename)\n",
    "        data = np.loadtxt(os.path.join(config.odir, config.savename), dtype=np.uint16)\n",
    "        pxlen=np.loadtxt(os.path.join(config.odir, \"pxlen.txt\"), dtype=np.uint16)\n",
    "        xidx=np.loadtxt(os.path.join(config.odir, \"xidx.txt\"), dtype=np.uint16)\n",
    "        yidx=np.loadtxt(os.path.join(config.odir, \"yidx.txt\"), dtype=np.uint16)\n",
    "        det=np.loadtxt(os.path.join(config.odir, \"detector.txt\"), dtype=np.uint16)\n",
    "        dt=np.loadtxt(os.path.join(config.odir, \"dt.txt\"), dtype=np.uint16)\n",
    "        print(\"loaded successfully\", config.savename)\n",
    "    \"---------------------------\\n\"\n",
    "    \"Memory usage:\\n\"\n",
    "    \"---------------------------\\n\"\n",
    "    utils.varsizes(locals().items())\n",
    "\n",
    "\n",
    "\n",
    "    #clear the bytestream from memory\n",
    "    del stream\n",
    "    gc.collect()\n",
    "\n",
    "    if config.DOCOLOURS == True:\n",
    "        rgbarray=colour.clcomplete(rvals, gvals, bvals, totalcounts)\n",
    "        colour.clshow(rgbarray)\n",
    "\n",
    "    print(\"DOCLUST\", config.DOCLUST)\n",
    "    if config.DOCLUST:\n",
    "        embedding, clusttimes = clustering.reduce(data)\n",
    "        categories = clustering.dokmeans(embedding, totalpx)\n",
    "\n",
    "        clustaverages=np.zeros([len(clustering.reducers),config.nclust,config.NCHAN])\n",
    "\n",
    "        for i in range(len(clustering.reducers)):\n",
    "            redname=clustering.getredname(i)\n",
    "            clustaverages[i]=clustering.sumclusters(data, categories[i])\n",
    "            \n",
    "            for j in range(config.nclust):\n",
    "                print(f'saving reducer {redname} cluster {j} with shape {clustaverages[i,j,:].shape}')\n",
    "                np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \"_\" + str(j) + \".txt\"), np.c_[energy, clustaverages[i,j,:]], fmt=['%1.3e','%1.6e'])\n",
    "            \n",
    "            print(f'saving combined file for {redname}')\n",
    "            np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \".txt\"), np.c_[energy, clustaverages[i,:,:].transpose(1,0)], fmt='%1.5e')             \n",
    "            #plt.plot(energy, clustaverages[i,j,:])\n",
    "        clustering.clustplt(embedding, categories, mapx, clusttimes)\n",
    "\n",
    "\n",
    "\n",
    "print(\"CLEAN EXIT\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "snip background\n",
    "https://stackoverflow.com/questions/57350711/baseline-correction-for-spectroscopic-data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          data: 528.1 MiB\n",
      "                         pxlen: 132.1 KiB\n",
      "                          xidx: 132.1 KiB\n",
      "                          yidx: 132.1 KiB\n",
      "                           det: 132.1 KiB\n",
      "                            dt: 132.1 KiB\n",
      "                          chan: 32.1 KiB\n",
      "                        energy: 32.1 KiB\n",
      "                       outchan: 32.1 KiB\n",
      "                        counts: 32.1 KiB\n"
     ]
    }
   ],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)\n",
    "\n",
    "utils.varsizes(locals().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script: /home/lachlan/CODEBASE/ReadoutXFM/config.py\n",
      "script path: /home/lachlan/CODEBASE/ReadoutXFM\n",
      "data path: /home/lachlan/CODEBASE/ReadoutXFM/data\n",
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/lachlan/CODEBASE/ReadoutXFM/config.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(clustering)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCLUST False\n",
      "REDUCER 1 of 2: PCA across 67600 elements\n",
      "REDUCER 2 of 2: UMAP across 67600 elements\n",
      "UMAP(min_dist=0.3, n_neighbors=30, verbose=True)\n",
      "Thu Sep 29 22:36:45 2022 Construct fuzzy simplicial set\n",
      "Thu Sep 29 22:36:46 2022 Finding Nearest Neighbors\n",
      "Thu Sep 29 22:36:46 2022 Building RP forest with 18 trees\n",
      "Thu Sep 29 22:36:57 2022 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Thu Sep 29 22:37:21 2022 Finished Nearest Neighbor Search\n",
      "Thu Sep 29 22:37:24 2022 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  27%| ██▋        54/200 [00:05]"
     ]
    }
   ],
   "source": [
    "print(\"DOCLUST\", config.DOCLUST)\n",
    "if True:\n",
    "    embedding, clusttimes = clustering.reduce(data)\n",
    "    categories = clustering.dokmeans(embedding, totalpx)\n",
    "\n",
    "    clustaverages=np.zeros([len(clustering.reducers),config.nclust,config.NCHAN])\n",
    "\n",
    "    for i in range(len(clustering.reducers)):\n",
    "        redname=clustering.getredname(i)\n",
    "        clustaverages[i]=clustering.sumclusters(data, categories[i])\n",
    "        \n",
    "        for j in range(config.nclust):\n",
    "            print(f'saving reducer {redname} cluster {j} with shape {clustaverages[i,j,:].shape}')\n",
    "            np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \"_\" + str(j) + \".txt\"), np.c_[energy, clustaverages[i,j,:]], fmt=['%1.3e','%1.6e'])\n",
    "        \n",
    "        print(f'saving combined file for {redname}')\n",
    "        np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \".txt\"), np.c_[energy, clustaverages[i,:,:].transpose(1,0)], fmt='%1.5e')             \n",
    "        #plt.plot(energy, clustaverages[i,j,:])\n",
    "    clustering.clustplt(embedding, categories, mapx, clusttimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(clustering)\n",
    "\n",
    "if config.DOCOLOURS == True:\n",
    "    rgbarray=colour.clcomplete(rvals, gvals, bvals, totalcounts)\n",
    "    colour.clshow(rgbarray)\n",
    "\n",
    "print(\"DOCLUST\", config.DOCLUST)\n",
    "if config.DOCLUST:\n",
    "    embedding, clusttimes = clustering.reduce(data)\n",
    "    categories = clustering.dokmeans(embedding, totalpx)\n",
    "\n",
    "    clustaverages=np.zeros([len(clustering.reducers),config.nclust,config.NCHAN])\n",
    "\n",
    "    for i in range(len(clustering.reducers)):\n",
    "        redname=clustering.getredname(i)\n",
    "        clustaverages[i]=clustering.sumclusters(data, categories[i])\n",
    "        \n",
    "        for j in range(config.nclust):\n",
    "            print(f'saving reducer {redname} cluster {j} with shape {clustaverages[i,j,:].shape}')\n",
    "            np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \"_\" + str(j) + \".txt\"), np.c_[energy, clustaverages[i,j,:]], fmt=['%1.3e','%1.6e'])\n",
    "        \n",
    "        print(f'saving combined file for {redname}')\n",
    "        np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \".txt\"), np.c_[energy, clustaverages[i,:,:].transpose(1,0)], fmt='%1.5e')             \n",
    "        #plt.plot(energy, clustaverages[i,j,:])\n",
    "    clustering.clustplt(embedding, categories, mapx, clusttimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "print(data[:,0:2500].shape)\n",
    "\n",
    "rdata=data[:,0:2500]\n",
    "\n",
    "#data=rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(clustering)\n",
    "\n",
    "utils.varsizes(locals().items())\n",
    "\n",
    "\n",
    "print(\"DOCLUST\", config.DOCLUST)\n",
    "\n",
    "if True:\n",
    "    embedding, clusttimes = clustering.reduce(data)\n",
    "    categories = clustering.dokmeans(embedding, totalpx)\n",
    "\n",
    "    clustaverages=np.zeros([len(clustering.reducers),config.nclust,config.NCHAN])\n",
    "\n",
    "    for i in range(len(clustering.reducers)):\n",
    "        redname=clustering.getredname(i)\n",
    "        clustaverages[i]=clustering.sumclusters(data, categories[i])\n",
    "        \n",
    "        for j in range(config.nclust):\n",
    "            print(f'saving reducer {redname} cluster {j} with shape {clustaverages[i,j,:].shape}')\n",
    "            np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \"_\" + str(j) + \".txt\"), np.c_[energy, clustaverages[i,j,:]], fmt=['%1.3e','%1.6e'])\n",
    "        \n",
    "        print(f'saving combined file for {redname}')\n",
    "        np.savetxt(os.path.join(config.odir, \"sum_\" + redname + \".txt\"), np.c_[energy, clustaverages[i,:,:].transpose(1,0)], fmt='%1.5e')             \n",
    "        #plt.plot(energy, clustaverages[i,j,:])\n",
    "    clustering.clustplt(embedding, categories, mapx, clusttimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del embedding\n",
    "del categories\n",
    "del clustaverages\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = np.loadtxt(os.path.join(config.odir, \"pxspec_dw.dat\"), dtype=np.uint16)\n",
    "\n",
    "print(data.shape)\n",
    "print(rdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rdata[200,50:100])\n",
    "print(data[200,50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.varsizes(locals().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workspec=clustaverages[1,4,:]\n",
    "\n",
    "#plt.xscale(\"log\")\n",
    "\n",
    "plt.xlim(0.5,25)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(0.04,1000)\n",
    "plt.plot(energy,workspec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline correction\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from scipy.signal import gaussian\n",
    "\n",
    "#pybaselines project looks great\n",
    "#https://pypi.org/project/pybaselines/\n",
    "\n",
    "#alternately code from\n",
    "#https://stackoverflow.com/questions/57350711/baseline-correction-for-spectroscopic-data\n",
    "\n",
    "def baseline_correction4(raman_spectra,lam,p,niter=10):\n",
    "    #according to \"Asymmetric Least Squares Smoothing\" by P. Eilers and H. Boelens\n",
    "    number_of_spectra = raman_spectra.index.size\n",
    "\n",
    "    #this is the code for the fitting procedure        \n",
    "    L = len(raman_spectra.columns)\n",
    "    w = np.ones(raman_spectra.shape[0]*raman_spectra.shape[1])\n",
    "\n",
    "    D = sparse.block_diag(np.tile(sparse.diags([1,-2,1],[0,-1,-2],shape=(L,L-2)),number_of_spectra),format='csr')\n",
    "\n",
    "    raman_spectra_flattened = raman_spectra.values.ravel()\n",
    "\n",
    "    for jj in range(int(niter)):\n",
    "        W = sparse.diags(w,format='csr')\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = spsolve(Z,w*raman_spectra_flattened,permc_spec='NATURAL')\n",
    "        w = p * (raman_spectra_flattened > z) + (1-p) * (raman_spectra_flattened < z)\n",
    "    #end of fitting procedure\n",
    "\n",
    "    baseline_data = pd.DataFrame(z.reshape(number_of_spectra,-1),index=raman_spectra.index,columns=raman_spectra.columns)\n",
    "    return baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct \n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "https://stackoverflow.com/questions/40059654/python-convert-a-bytes-array-into-json-format\n",
    "\"\"\"\n",
    "\n",
    "headerstream=stream[2:headerlen+2]\n",
    "\n",
    "headerstream = headerstream.decode('utf8')\n",
    "\"\"\"\n",
    "print(header[-100])\n",
    "print(\"--------------------------\")\n",
    "print(jsonheader)\n",
    "print(\"--------------------------\")\n",
    "#print(jsonheader[1300:1600])\n",
    "#print(\"--------------------------\")\n",
    "print(jsonheader[1450:1480])\n",
    "print(len(jsonheader))\n",
    "\"\"\"\n",
    "\n",
    "headerdict = json.loads(headerstream)\n",
    "headerdump = json.dumps(headerdict, indent=4, sort_keys=False)\n",
    "\n",
    "print(headerdump)\n",
    "print(\"KEYS\")\n",
    "print(headerdict.keys())\n",
    "nmapx=headerdict['File Header']['Xres']\n",
    "nmapy=headerdict['File Header']['Yres']\n",
    "\n",
    "print(nmapx,nmapy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(f)\n",
    "\n",
    "\n",
    "with open(f) as file: # rb = read binary\n",
    "  \n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    jsondata = json.load(file)\n",
    "    \n",
    "    # Iterating through the json\n",
    "    # list\n",
    "    for i in jsondata['emp_details']:\n",
    "        print(i)\n",
    "    \n",
    "    # Closing file\n",
    "    #f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('venv_readoutxfm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb96fd94dfdeddb3941b742ac09afeae622274abf603b01f6c95366e7b99940d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
